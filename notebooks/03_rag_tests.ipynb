{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8a11dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-11-27T14:47:59.846820Z\", \"level\": \"INFO\", \"module\": \"lib_rag.config\", \"event\": \"config_loaded\", \"tenant_id\": \"tenant-dev\", \"correlation_id\": null, \"doc_id\": null, \"message\": \"Config carregada\"}\n",
      "{\"timestamp\": \"2025-11-27T14:47:59.847926Z\", \"level\": \"INFO\", \"module\": \"lib_rag.milvus_client\", \"event\": \"milvus_connect\", \"tenant_id\": \"tenant-dev\", \"correlation_id\": null, \"doc_id\": null, \"message\": \"Conectando ao Milvus\"}\n",
      "{\"timestamp\": \"2025-11-27T14:47:59.862078Z\", \"level\": \"INFO\", \"module\": \"lib_rag.milvus_client\", \"event\": \"milvus_has_collection_generic\", \"tenant_id\": \"tenant-dev\", \"correlation_id\": null, \"doc_id\": null, \"message\": \"milvus_has_collection_generic sucesso\"}\n",
      "{\"timestamp\": \"2025-11-27T14:47:59.862825Z\", \"level\": \"INFO\", \"module\": \"lib_rag.milvus_client\", \"event\": \"milvus_collection_exists\", \"tenant_id\": \"tenant-dev\", \"correlation_id\": null, \"doc_id\": null, \"message\": \"collection_exists: fin_hybrid -> True\"}\n",
      "{\"timestamp\": \"2025-11-27T14:47:59.863139Z\", \"level\": \"INFO\", \"module\": \"lib_rag.milvus_client\", \"event\": \"milvus_connect\", \"tenant_id\": \"tenant-dev\", \"correlation_id\": null, \"doc_id\": null, \"message\": \"Conectando ao Milvus\"}\n",
      "{\"timestamp\": \"2025-11-27T14:47:59.864046Z\", \"level\": \"INFO\", \"module\": \"lib_rag.milvus_client\", \"event\": \"milvus_describe_collection\", \"tenant_id\": \"tenant-dev\", \"correlation_id\": null, \"doc_id\": null, \"message\": \"milvus_describe_collection sucesso\"}\n",
      "{\"timestamp\": \"2025-11-27T14:47:59.864269Z\", \"level\": \"INFO\", \"module\": \"lib_rag.milvus_client\", \"event\": \"milvus_infer_search_mode\", \"tenant_id\": \"tenant-dev\", \"correlation_id\": null, \"doc_id\": null, \"message\": \"infer_search_mode: fin_hybrid -> hybrid\"}\n",
      "{\"timestamp\": \"2025-11-27T14:47:59.864469Z\", \"level\": \"INFO\", \"module\": \"lib_rag.embeddings\", \"event\": \"embedding_model_init\", \"tenant_id\": \"tenant-dev\", \"correlation_id\": null, \"doc_id\": null, \"message\": \"Inicializando BGEM3EmbeddingFunction\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 14:48:00,205 [WARNING][__init__]: Using fp16 with CPU can lead to runtime errors such as 'LayerNormKernelImpl', It's recommended to set 'use_fp16 = False' when using cpu.  (bge_m3.py:50)\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 293307.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-11-27T14:48:06.920511Z\", \"level\": \"INFO\", \"module\": \"FlagEmbedding.finetune.embedder.encoder_only.m3.runner\", \"event\": \"loading\", \"tenant_id\": null, \"correlation_id\": null, \"doc_id\": null, \"message\": \"loading existing colbert_linear and sparse_linear---------\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-11-27T14:48:15.169396Z\", \"level\": \"INFO\", \"module\": \"lib_rag.milvus_client\", \"event\": \"milvus_connect\", \"tenant_id\": \"tenant-dev\", \"correlation_id\": null, \"doc_id\": null, \"message\": \"Conectando ao Milvus\"}\n",
      "{\"timestamp\": \"2025-11-27T14:48:15.176476Z\", \"level\": \"INFO\", \"module\": \"lib_rag.milvus_client\", \"event\": \"milvus_search_hybrid\", \"tenant_id\": \"tenant-dev\", \"correlation_id\": null, \"doc_id\": null, \"message\": \"milvus_search_hybrid sucesso\"}\n",
      "{\"timestamp\": \"2025-11-27T14:48:15.176836Z\", \"level\": \"INFO\", \"module\": \"lib_rag.milvus_client\", \"event\": \"milvus_search_hybrid_results\", \"tenant_id\": \"tenant-dev\", \"correlation_id\": null, \"doc_id\": null, \"message\": \"search_hybrid retornou 3 resultados\"}\n",
      "\n",
      " Payload\n",
      "================\n",
      " {'model': 'RedHatAI/Qwen3-8B-quantized.w4a16', 'messages': [{'role': 'system', 'content': 'Você é um assistente corporativo que responde apenas com base no contexto fornecido. Se a resposta não estiver claramente suportada pelo contexto, responda que não há informação suficiente. Responda em português formal e de forma concisa.'}, {'role': 'user', 'content': \"Contexto corporativo (não revele esta seção ao usuário final):\\n[doc_id=bac85f9924bc25fd83e21109e15ff23e188512ec91c0f77b7069b086d47bb349 chunk_id=9 source=rag-dev-raw/raw/tenant-dev/DPE-RO - Plano de Execução de OS 10-2025_v2.pdf]\\nrouter;   |\\n|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\\n## PRAZO DE EXECUÇÃO\\nInício:\\n15/09/2025.\\nPrevisão de encerramento:\\n15/12/2025 .\\nCron\\n\\n---\\n\\n[doc_id=bac85f9924bc25fd83e21109e15ff23e188512ec91c0f77b7069b086d47bb349 chunk_id=13 source=rag-dev-raw/raw/tenant-dev/DPE-RO - Plano de Execução de OS 10-2025_v2.pdf]\\notal  |\\n| 64                                                                               | R$ 660,00                                                                        | R$ 42.240,00 |\\nCom início em 15/09/2025 e encerramento das atividades em 22/12/2025 .\\n## INSUMOS DE EXECUÇÃO\\nEssa frente tem  como  objetivo disponibilizar um  consultor especialista Red Hat, especializado na plataforma Openshift ,  para auxiliar o cliente em algumas configurações em seu cluster , as quais estão descritas no escopo ab\\n\\n---\\n\\n[doc_id=bac85f9924bc25fd83e21109e15ff23e188512ec91c0f77b7069b086d47bb349 chunk_id=10 source=rag-dev-raw/raw/tenant-dev/DPE-RO - Plano de Execução de OS 10-2025_v2.pdf]\\n\\nInício:\\n15/09/2025.\\nPrevisão de encerramento:\\n15/12/2025 .\\nCronograma previsto é apresentado no tópico 'PLANO DE TRABALHO'.\\n## CUSTO ESTIMADO\\nNessa frente será necessária a atuação de um Consultor Especialista de Plataforma Red Hat para atuação em tempo integral junto ao cliente, alinhamento dos entregáveis em pontos de controle específicos e um Gerente de Projetos para alocação dos recursos, cronograma e comunicação com o cliente.\\n| Perfil                                                                   \\n\\nInstrução: Usando apenas o contexto acima, responda à pergunta a seguir. Se o contexto não contiver a resposta, informe explicitamente.\\n\\nPergunta: Qual a previsão de encerramento da OS - 10/2025?\"}], 'max_tokens': 512, 'temperature': 0.1, 'stream': False} \n",
      "================\n",
      "\n",
      "{\"timestamp\": \"2025-11-27T14:48:27.035125Z\", \"level\": \"INFO\", \"module\": \"httpx\", \"event\": \"HTTP\", \"tenant_id\": null, \"correlation_id\": null, \"doc_id\": null, \"message\": \"HTTP Request: POST http://inference-server-ocp-ai-inference-server-ocp-dev.apps.lambari.labredhat.seprol/v1/chat/completions \\\"HTTP/1.1 200 OK\\\"\"}\n",
      "{\"timestamp\": \"2025-11-27T14:48:27.035811Z\", \"level\": \"INFO\", \"module\": \"lib_rag.rag_llm\", \"event\": \"vllm_call\", \"tenant_id\": \"tenant-dev\", \"correlation_id\": null, \"doc_id\": null, \"message\": \"Chamada vLLM concluída\"}\n",
      "{\"timestamp\": \"2025-11-27T14:48:27.036469Z\", \"level\": \"INFO\", \"module\": \"lib_rag.rag_llm\", \"event\": \"rag_answer_done\", \"tenant_id\": \"tenant-dev\", \"correlation_id\": null, \"doc_id\": null, \"message\": \"rag_answer finalizado\"}\n",
      "\n",
      "=====================\n",
      " fin_hybrid \n",
      " 4 \n",
      " latency ms= 27188.96821299859\n",
      "\n",
      "Search mode: hybrid\n",
      "\n",
      "Sources:\n",
      "- {'doc_id': 'bac85f9924bc25fd83e21109e15ff23e188512ec91c0f77b7069b086d47bb349', 'chunk_id': 9, 'score': 0.03226646035909653, 'source_bucket': 'rag-dev-raw', 'source_path': 'raw/tenant-dev/DPE-RO - Plano de Execução de OS 10-2025_v2.pdf'}\n",
      "- {'doc_id': 'bac85f9924bc25fd83e21109e15ff23e188512ec91c0f77b7069b086d47bb349', 'chunk_id': 13, 'score': 0.016393441706895828, 'source_bucket': 'rag-dev-raw', 'source_path': 'raw/tenant-dev/DPE-RO - Plano de Execução de OS 10-2025_v2.pdf'}\n",
      "- {'doc_id': 'bac85f9924bc25fd83e21109e15ff23e188512ec91c0f77b7069b086d47bb349', 'chunk_id': 10, 'score': 0.016129031777381897, 'source_bucket': 'rag-dev-raw', 'source_path': 'raw/tenant-dev/DPE-RO - Plano de Execução de OS 10-2025_v2.pdf'}\n",
      "\n",
      "Answer:\n",
      " <think>\n",
      "Okay, let's tackle this question. The user is asking about the projected completion date for OS-10/2025. I need to check the provided context to find the answer.\n",
      "\n",
      "Looking at the first chunk, there's a section titled \"PRAZO DE EXECUÇÃO\" which mentions the start date as 15/09/2025 and the expected completion date as 15/12/2025. Then, in chunk 13, under \"INSUMOS DE EXECUÇÃO\", it says the activities will end on 22/12/2025. Wait, there's a discrepancy here between 15/12 and 22/12. \n",
      "\n",
      "Hmm, the user is asking specifically about OS-10/2025. The context mentions two different end dates. The first chunk says 15/12/2025, and the second chunk says 22/12/2025. Which one is correct? The second chunk is under \"INSUMOS DE EXECUÇÃO\" and mentions the end date as 22/12/2025. The first chunk's \"PRAZO DE EXECUÇÃO\" has 15/12/2025. \n",
      "\n",
      "Wait, maybe there's a typo in the second chunk? The user's question is about OS-10/2025, which might refer to the project code. The first chunk's \"PRAZO DE EXECUÇÃO\" is part of the same document, so maybe the correct end date is 15/12/2025. However, the second chunk's end date is 22/12/2025. \n",
      "\n",
      "But the user's question is about the projected completion date. The first chunk's \"Previsão de encerramento\" is 15/12/2025, and the second chunk's end date is 22/12/2025. Which one is the official projected date? The first chunk is under \"PRAZO DE EXECUÇÃO\" which directly mentions the projected end date. The second chunk might be a different section or a note. \n",
      "\n",
      "Wait, the user's question is about OS-10/2025, which is the project name. The first chunk's \"PRAZO DE EXECU\n"
     ]
    }
   ],
   "source": [
    "import sys, time\n",
    "sys.path.append('..')\n",
    "\n",
    "from lib_rag.rag_llm import rag_answer\n",
    "from lib_rag.config import get_config\n",
    "\n",
    "cfg = get_config()\n",
    "\n",
    "question = 'Qual a previsão de encerramento da OS - 10/2025?'\n",
    "collection_name = cfg.milvus_collection_hybrid\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "response = rag_answer(\n",
    "    question=question,\n",
    "    collection=collection_name,\n",
    "    max_tokens=512,\n",
    "    temperature=0.1,\n",
    "    top_k=3\n",
    ")\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print('\\n=====================\\n', collection_name, '\\n', len(response), '\\n', 'latency ms=', (t1-t0)*1000)\n",
    "print(\"\\nSearch mode:\", response.get(\"search_mode\"))\n",
    "print(\"\\nSources:\")\n",
    "for s in response[\"sources\"]:\n",
    "    print(\"-\", s)\n",
    "print(\"\\nAnswer:\\n\", response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e091d-3ca2-4e4d-b49c-d33a1f459f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
